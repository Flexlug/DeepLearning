{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Очистка Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset представляет из себя набор из картинок формата, к каждой из которых прилагается текстовый файл с соответствующими картинке тегами.\n",
    "Загрузим все картинки и прикрепим к каждой из них теги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import paths\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetImage:\n",
    "    def __init__(self, tagsPath):\n",
    "        self.tagsPath = tagsPath\n",
    "        self.imagePath = tagsPath[:-4] + '.jpg'\n",
    "        self.id = int(tagsPath.split(os.sep)[-1][:-4])\n",
    "        self.tags = set()\n",
    "        with open(tagsPath) as file:\n",
    "            rawTagLines = file.readlines()\n",
    "            for tagLine in rawTagLines:\n",
    "                for tag in tagLine.split(','):\n",
    "                    self.tags |= {tag.strip()}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Узнаем, какие у нас расширения встречаются в Dataset. Ожидаем, что мы увидим только .txt и .jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'jpg', 'txt'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extensions = set()\n",
    "\n",
    "for file in paths.list_files(\"./dataset\"):\n",
    "    extensions.add(file.split('.')[-1])\n",
    "\n",
    "extensions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все файлы являются либо .txt, либо .jpg файлами. OK"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подсчитаем количество .txt и .jpg файлов. Их должно быть одинаковое количество"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'jpg': 30450, 'txt': 30450}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extDict = { 'jpg': 0, 'txt': 0 }\n",
    "\n",
    "for file in paths.list_files(\"./dataset\"):\n",
    "    fileExt = file.split('.')[-1]\n",
    "    extDict[fileExt] += 1\n",
    "\n",
    "extDict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество совпадает. ОК"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим изображения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "\n",
    "for file in tqdm(paths.list_files(\"./dataset\"), 'Loading Images'):\n",
    "    if file.endswith('.txt'):\n",
    "        img = DatasetImage(file)\n",
    "        images.append(img)\n",
    "\n",
    "len(images)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим встречающиеся теги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tags(images):\n",
    "    allTagsSet = set()\n",
    "\n",
    "    for image in images:\n",
    "        allTagsSet |= set(image.tags)\n",
    "\n",
    "    tagsDict = {x: 0 for x in list(allTagsSet)}\n",
    "\n",
    "    for img in images:\n",
    "        for tag in img.tags:\n",
    "            tagsDict[tag] += 1\n",
    "\n",
    "    sortedTagsDictItems = sorted(tagsDict.items(), key=lambda item: item[1])\n",
    "    sortedTagsDictItems.reverse()\n",
    "\n",
    "    sortedTagsDict = dict(sortedTagsDictItems)\n",
    "\n",
    "    for key, value in sortedTagsDict.items():\n",
    "        print(f'{key}: {value}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем список всех тегов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_tags(images)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функции для обработки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MappedTouhouImage:\n",
    "    def __init__(self, image, character_name):\n",
    "        self.id = image.id\n",
    "        self.character_name = character_name\n",
    "        self.imagePath = image.imagePath\n",
    "        self.tags = image.tags\n",
    "        self.tagsPath = image.tagsPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersonStats:\n",
    "    def __init__(self):\n",
    "        self.other = 0\n",
    "        self.solo = 0\n",
    "        self.main = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_images_with_tags_to(images, selected_tags, folder_name):\n",
    "    selected_images = []\n",
    "\n",
    "    new_dir_path = os.path.join('./temp', folder_name)\n",
    "    if not os.path.exists(new_dir_path):\n",
    "        os.mkdir(new_dir_path)\n",
    "\n",
    "    for image in images:\n",
    "        if len(image.tags & selected_tags) != 0:\n",
    "            selected_images.append(image)\n",
    "\n",
    "    if (len(selected_images) == 0):\n",
    "        print(\"Nothing to copy\")\n",
    "        return images\n",
    "\n",
    "    movedImages = []\n",
    "\n",
    "    for image in tqdm(selected_images, f'Copying images to {folder_name}'):\n",
    "        newGenericPath = os.path.join(new_dir_path, str(image.id))\n",
    "\n",
    "        if (not os.path.exists(image.imagePath)):\n",
    "            print(f'WARNING! IMAGE {image.imagePath} DOES NOT EXISTS!')\n",
    "            continue\n",
    "\n",
    "        if (not os.path.exists(image.imagePath)):\n",
    "            print(f'WARNING! IMAGE EXISTS BUT TAGS {image.tagsPath} DOES NOT EXISTS!')\n",
    "            continue\n",
    "\n",
    "        shutil.copy(image.imagePath, newGenericPath + '.jpg')\n",
    "        shutil.copy(image.tagsPath, newGenericPath + '.txt')\n",
    "\n",
    "        movedImages.append(DatasetImage(newGenericPath + '.txt'))\n",
    "\n",
    "    return movedImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_images_with_tags_to(images, selected_tags, folder_name):\n",
    "    selected_images = []\n",
    "\n",
    "    new_dir_path = os.path.join('./temp', folder_name)\n",
    "    if not os.path.exists(new_dir_path):\n",
    "        os.mkdir(new_dir_path)\n",
    "\n",
    "    for image in images:\n",
    "        if len(image.tags & selected_tags) != 0:\n",
    "            selected_images.append(image)\n",
    "\n",
    "    if (len(selected_images) == 0):\n",
    "        print(\"Nothing to move\")\n",
    "        return [], images\n",
    "\n",
    "    movedImages = []\n",
    "    clearedImages = images.copy()\n",
    "\n",
    "    for image in tqdm(selected_images, f'Moving images to {folder_name}'):\n",
    "        newGenericPath = os.path.join(new_dir_path, str(image.id))\n",
    "\n",
    "        if (not os.path.exists(image.imagePath)):\n",
    "            print(f'WARNING! IMAGE {image.imagePath} DOES NOT EXISTS!')\n",
    "            continue\n",
    "\n",
    "        if (not os.path.exists(image.imagePath)):\n",
    "            print(f'WARNING! IMAGE EXISTS BUT TAGS {image.tagsPath} DOES NOT EXISTS!')\n",
    "            continue\n",
    "\n",
    "        shutil.move(image.imagePath, newGenericPath + '.jpg')\n",
    "        shutil.move(image.tagsPath, newGenericPath + '.txt')\n",
    "\n",
    "        movedImages.append(DatasetImage(newGenericPath + '.txt'))\n",
    "        clearedImages.remove(image)\n",
    "\n",
    "    return movedImages, clearedImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_images_to_final(movingImages, folder_name):\n",
    "    new_dir_path = os.path.join('./mapped_dataset', folder_name)\n",
    "    if not os.path.exists(new_dir_path):\n",
    "        os.mkdir(new_dir_path)\n",
    "\n",
    "    if (len(movingImages) == 0):\n",
    "        print(\"Nothing to move\")\n",
    "        return [], movingImages\n",
    "\n",
    "    movedImages = []\n",
    "\n",
    "    for image in tqdm(movingImages, f'Moving images to final: {folder_name}'):\n",
    "        newGenericPath = os.path.join(new_dir_path, str(image.id))\n",
    "\n",
    "        if (not os.path.exists(image.imagePath)):\n",
    "            print(f'WARNING! IMAGE {image.imagePath} DOES NOT EXISTS!')\n",
    "            continue\n",
    "\n",
    "        if (not os.path.exists(image.imagePath)):\n",
    "            print(f'WARNING! IMAGE EXISTS BUT TAGS {image.tagsPath} DOES NOT EXISTS!')\n",
    "            continue\n",
    "\n",
    "        shutil.move(image.imagePath, newGenericPath + '.jpg')\n",
    "        shutil.move(image.tagsPath, newGenericPath + '.txt')\n",
    "\n",
    "        movedImages.append(DatasetImage(newGenericPath + '.txt'))\n",
    "\n",
    "    return movedImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleared_images = []\n",
    "moved_images = []\n",
    "persons_img_count = dict()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Процесс обработки:\n",
    "1. Выбираем любого персонажа из [Touhou Wiki](https://touhou.fandom.com/wiki/Category:Characters)\n",
    "2. Ищем теги, которые соответствуют этому персонажу. Как правило их 1-2. Добавлем эти теги в следущем формате:\n",
    "```\n",
    "[имя_персонажа]: {\n",
    "    [тег1],\n",
    "    [тег2]\n",
    "}\n",
    "```\n",
    "`имя_персонажа` в данном случае это название директории, куда будут сгружаться картинки.\n",
    "\n",
    "3. Выполняем все ячейки до конца.\n",
    "\n",
    "#### Что происходит при обработке:\n",
    "1. Все найденные с тегами персонажа изображения копируются в директорию `./temp/[имя_персонажа]`\n",
    "2. Отфильтровываются изображения, которые нам точно не понадобятся. Это:\n",
    "- NSFW контент;\n",
    "- Изображения персонажа, которые сильно отличаются от его типичного стиля\n",
    "\n",
    "Такие изображения отправляются в `./temp/[имя_персонажа]/other`\n",
    "\n",
    "3. Останутся картинки, на которых может быть несколько персонажей сразу. Это не так плохо, но лучше всего будет отфильтровать картинки, где есть только рассматриваемый персонаж. Поэтому отправляем в отдельную директорию `./temp/[имя_персонажа]/solo` все картинки с тегами `solo`, `1girl`. \n",
    "\n",
    "4. Картинки из `./temp/[имя_персонажа]/solo` перемещаем в `./mapped_dataset/[имя_персонажа]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_tags(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons = {\n",
    "    'alice_margatroid': {\n",
    "        'alice margatroid (pc-98)',\n",
    "        'alice margatroid'\n",
    "    }\n",
    "\n",
    "    'flandre_scarlet': {\n",
    "        'flandre scarlet',\n",
    "        'flandre scarlet (vampire pursuing the hunter)'\n",
    "    },\n",
    "\n",
    "    'hakurei_reimu': {\n",
    "        'hakurei reimu',\n",
    "        'hakurei reimu (pc-98)',\n",
    "    },\n",
    "\n",
    "    'remilia_scarlet': {\n",
    "        'remilia scarlet',\n",
    "    },\n",
    "\n",
    "    'ibuki_suika': {\n",
    "        'ibuki suika',        \n",
    "    },\n",
    "\n",
    "    'yakumo_yukari': {\n",
    "        'yakumo yukari',        \n",
    "    },\n",
    "\n",
    "    'komeiji_satori': {\n",
    "        'komeiji satori',\n",
    "        'foul detective satori',\n",
    "    },\n",
    "\n",
    "    'konpaku_youmu': {\n",
    "        'konpaku youmu',\n",
    "        'konpaku youmu (ghost)'\n",
    "    },\n",
    "\n",
    "    'komeiji_koishi': {\n",
    "        'komeiji koishi',\n",
    "        'koishi day'\n",
    "    },\n",
    "\n",
    "    'kirisame_marisa': {\n",
    "        'kirisame marisa',\n",
    "        'kirisame marisa (pc-98)',\n",
    "    },\n",
    "\n",
    "    'izayoi_sakuya': {\n",
    "        'izayoi sakuya'\n",
    "    },\n",
    "\n",
    "    'rumia': {\n",
    "        'rumia'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_folder_name = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_copy():\n",
    "    if (not person_folder_name in persons_img_count):\n",
    "        persons_img_count[person_folder_name] = PersonStats()\n",
    "\n",
    "    selected_tags = persons[person_folder_name]\n",
    "\n",
    "    cleared_images = copy_images_with_tags_to(images, selected_tags, person_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_nsfw_other():\n",
    "    selected_tags = { \n",
    "        'tentacles',\n",
    "        'yuri',\n",
    "        'nude',\n",
    "        'cosplay'\n",
    "        'sex', \n",
    "        'group sex',\n",
    "        'vaginal',\n",
    "        'penis',\n",
    "        'ass', \n",
    "        'used condom', \n",
    "        'spread legs', \n",
    "        'imminent vaginal',\n",
    "        'imminent rape',\n",
    "        'masturbation',\n",
    "        'nipples',\n",
    "        'huge breasts', \n",
    "        '1boy',\n",
    "        'cum',\n",
    "        'bikini',\n",
    "        'skirt lift',\n",
    "        'lifted by self',\n",
    "        'underwear',\n",
    "        'underwear only'\n",
    "        'alternate costume',\n",
    "        'santa costume',\n",
    "        'swimsuit',\n",
    "        'loli',\n",
    "        'toes',\n",
    "        'cosplay',\n",
    "        'animal ears',\n",
    "        'rabbit ears',\n",
    "        'animal ears', }\n",
    "\n",
    "    moved_images, cleared_images = move_images_with_tags_to(cleared_images, selected_tags, f'{person_folder_name}\\\\other')\n",
    "    persons_img_count[person_folder_name].other = len(moved_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_solo():\n",
    "    selected_tags = {\n",
    "        'solo',\n",
    "        '1girl'\n",
    "    }\n",
    "\n",
    "    moved_images, cleared_images = move_images_with_tags_to(cleared_images, selected_tags, f'{person_folder_name}\\\\solo')\n",
    "    persons_img_count[person_folder_name].solo = len(moved_images)\n",
    "    persons_img_count[person_folder_name].main = len(cleared_images)\n",
    "\n",
    "    \n",
    "    move_images_to_final(moved_images, person_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats():\n",
    "    sortedPersonsDictItems = sorted(persons_img_count.items(), key=lambda item: item[1].solo + item[1].main + item[1].other)\n",
    "    sortedPersonsDictItems.reverse()\n",
    "\n",
    "    persons_img_count = dict(sortedPersonsDictItems)\n",
    "\n",
    "    for key, value in persons_img_count.items():\n",
    "        print(f'{key:20} - solo: {value.solo:4}, main: {value.main:4}, nsfw/other: {value.other:4}')\n",
    "\n",
    "    classes_count = len(persons)\n",
    "    total_images = sum(value.main + value.solo + value.other for key, value in persons_img_count.items())\n",
    "    print(f'Total images: {total_images}')\n",
    "    print(f'Total classes: {classes_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images to alice_margatroid: 100%|██████████| 523/523 [00:06<00:00, 84.30it/s] \n",
      "Moving images to alice_margatroid\\other: 100%|██████████| 156/156 [00:02<00:00, 71.36it/s]\n",
      "Moving images to alice_margatroid\\solo: 100%|██████████| 266/266 [00:05<00:00, 46.03it/s]\n",
      "Moving images to final: alice_margatroid: 100%|██████████| 266/266 [00:00<00:00, 272.76it/s]\n",
      "Copying images to flandre_scarlet: 100%|██████████| 2220/2220 [00:32<00:00, 68.75it/s] \n",
      "Moving images to flandre_scarlet\\other: 100%|██████████| 552/552 [00:10<00:00, 51.64it/s] \n",
      "Moving images to flandre_scarlet\\solo: 100%|██████████| 1338/1338 [00:26<00:00, 50.20it/s] \n",
      "Moving images to final: flandre_scarlet: 100%|██████████| 1338/1338 [00:06<00:00, 207.42it/s]\n",
      "Copying images to hakurei_reimu: 100%|██████████| 2173/2173 [00:56<00:00, 38.55it/s] \n",
      "Moving images to hakurei_reimu\\other: 100%|██████████| 492/492 [00:07<00:00, 69.15it/s] \n",
      "Moving images to hakurei_reimu\\solo: 100%|██████████| 1301/1301 [00:24<00:00, 53.62it/s] \n",
      "Moving images to final: hakurei_reimu: 100%|██████████| 1301/1301 [00:06<00:00, 204.10it/s]\n",
      "Copying images to remilia_scarlet: 100%|██████████| 1338/1338 [00:47<00:00, 28.16it/s]\n",
      "Moving images to remilia_scarlet\\other: 100%|██████████| 259/259 [00:06<00:00, 38.28it/s] \n",
      "Moving images to remilia_scarlet\\solo: 100%|██████████| 814/814 [00:15<00:00, 50.95it/s] \n",
      "Moving images to final: remilia_scarlet: 100%|██████████| 814/814 [00:03<00:00, 218.37it/s]\n",
      "Copying images to ibuki_suika: 100%|██████████| 195/195 [00:06<00:00, 28.56it/s]\n",
      "Moving images to ibuki_suika\\other: 100%|██████████| 40/40 [00:00<00:00, 242.99it/s]\n",
      "Moving images to ibuki_suika\\solo: 100%|██████████| 120/120 [00:00<00:00, 203.39it/s]\n",
      "Moving images to final: ibuki_suika: 100%|██████████| 120/120 [00:00<00:00, 241.56it/s]\n",
      "Copying images to yakumo_yukari: 100%|██████████| 596/596 [00:24<00:00, 23.84it/s]\n",
      "Moving images to yakumo_yukari\\other: 100%|██████████| 172/172 [00:01<00:00, 117.33it/s]\n",
      "Moving images to yakumo_yukari\\solo: 100%|██████████| 309/309 [00:02<00:00, 103.37it/s]\n",
      "Moving images to final: yakumo_yukari: 100%|██████████| 309/309 [00:01<00:00, 210.80it/s]\n",
      "Copying images to komeiji_satori: 100%|██████████| 887/887 [00:37<00:00, 23.68it/s]\n",
      "Moving images to komeiji_satori\\other: 100%|██████████| 205/205 [00:00<00:00, 235.68it/s]\n",
      "Moving images to komeiji_satori\\solo: 100%|██████████| 433/433 [00:06<00:00, 71.66it/s] \n",
      "Moving images to final: komeiji_satori: 100%|██████████| 433/433 [00:01<00:00, 229.96it/s]\n",
      "Copying images to konpaku_youmu: 100%|██████████| 1386/1386 [00:56<00:00, 24.54it/s]\n",
      "Moving images to konpaku_youmu\\other: 100%|██████████| 328/328 [00:04<00:00, 65.94it/s] \n",
      "Moving images to konpaku_youmu\\solo: 100%|██████████| 969/969 [00:16<00:00, 57.09it/s] \n",
      "Moving images to final: konpaku_youmu: 100%|██████████| 969/969 [00:04<00:00, 206.87it/s]\n",
      "Copying images to komeiji_koishi: 100%|██████████| 2135/2135 [01:39<00:00, 21.35it/s]\n",
      "Moving images to komeiji_koishi\\other: 100%|██████████| 374/374 [00:06<00:00, 60.23it/s] \n",
      "Moving images to komeiji_koishi\\solo: 100%|██████████| 1415/1415 [00:29<00:00, 47.24it/s]\n",
      "Moving images to final: komeiji_koishi: 100%|██████████| 1415/1415 [00:07<00:00, 197.87it/s]\n",
      "Copying images to kirisame_marisa: 100%|██████████| 1695/1695 [01:14<00:00, 22.86it/s]\n",
      "Moving images to kirisame_marisa\\other: 100%|██████████| 368/368 [00:05<00:00, 61.69it/s] \n",
      "Moving images to kirisame_marisa\\solo: 100%|██████████| 964/964 [00:17<00:00, 53.59it/s] \n",
      "Moving images to final: kirisame_marisa: 100%|██████████| 964/964 [00:04<00:00, 195.83it/s]\n",
      "Copying images to izayoi_sakuya: 100%|██████████| 960/960 [00:38<00:00, 25.17it/s]\n",
      "Moving images to izayoi_sakuya\\other: 100%|██████████| 300/300 [00:06<00:00, 47.39it/s] \n",
      "Moving images to izayoi_sakuya\\solo: 100%|██████████| 551/551 [00:09<00:00, 59.15it/s] \n",
      "Moving images to final: izayoi_sakuya: 100%|██████████| 551/551 [00:02<00:00, 220.58it/s]\n",
      "Copying images to rumia: 100%|██████████| 298/298 [00:12<00:00, 24.51it/s]\n",
      "Moving images to rumia\\other: 100%|██████████| 65/65 [00:00<00:00, 216.15it/s]\n",
      "Moving images to rumia\\solo: 100%|██████████| 217/217 [00:02<00:00, 90.38it/s] \n",
      "Moving images to final: rumia: 100%|██████████| 217/217 [00:00<00:00, 238.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flandre_scarlet      - solo: 1338, main:  330, nsfw/other:  552\n",
      "hakurei_reimu        - solo: 1301, main:  380, nsfw/other:  492\n",
      "komeiji_koishi       - solo: 1415, main:  346, nsfw/other:  374\n",
      "kirisame_marisa      - solo:  964, main:  363, nsfw/other:  368\n",
      "konpaku_youmu        - solo:  969, main:   89, nsfw/other:  328\n",
      "remilia_scarlet      - solo:  814, main:  265, nsfw/other:  259\n",
      "izayoi_sakuya        - solo:  551, main:  109, nsfw/other:  300\n",
      "komeiji_satori       - solo:  433, main:  249, nsfw/other:  205\n",
      "yakumo_yukari        - solo:  309, main:  115, nsfw/other:  172\n",
      "alice_margatroid     - solo:  266, main:  101, nsfw/other:  156\n",
      "rumia                - solo:  217, main:   16, nsfw/other:   65\n",
      "ibuki_suika          - solo:  120, main:   35, nsfw/other:   40\n",
      "Total images: 14406\n",
      "Total classes: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for person, tags in persons.items():\n",
    "    person_folder_name = person\n",
    "\n",
    "    initial_copy()\n",
    "    filter_nsfw_other()\n",
    "    filter_solo()\n",
    "\n",
    "print_stats()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "19557e958749074bb0ba5b33e1f158a275d605dc21a90d1d0263ca1cd87ac03b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
