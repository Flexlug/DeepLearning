{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q5dU9PbNgcsR"
   },
   "source": [
    "# **Практическая работа №8. Генеративно-состязательная сеть (GAN). Часть 1**\n",
    "\n",
    "[**Ссылка на код с пары**](https://colab.research.google.com/drive/1i3NlGFJbY6hvm-ropSFobW9_nqUcqzPS?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TAgPoBU33lCF"
   },
   "source": [
    "# Примечание:\n",
    "\n",
    "Не забывайте периодически сохранять параметры модели. Функции для этого описаны в теоретической части. В случае приостановки процесса обучения из-за перегрузки ОЗУ, Вы сможете загрузить последние предобученные параметры и продолжить обучение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5vsrYXt1Rk8"
   },
   "source": [
    "# **Задание №1.** Обучите генератор воспризводить примитивные изображения. Датасет выберите по желанию. ([Пример](https://www.kaggle.com/datasets/sagyamthapa/handwritten-math-symbols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Взят датасет отсюда:\n",
    "https://www.kaggle.com/datasets/tatianasnwrt/russian-handwritten-letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "al9koHX-2OGF"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imutils import paths\n",
    "import random \n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = 28\n",
    "img_cols = 28\n",
    "channels = 1\n",
    "img_shape = (img_rows, img_cols, channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Конструктор генератора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    noise_shape = (100,)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(256, input_shape=noise_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dense(1024))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    \n",
    "    model.add(Dense(np.prod(img_shape), activation='tanh'))\n",
    "    model.add(Reshape(img_shape))\n",
    "\n",
    "    noise = Input(shape=noise_shape)\n",
    "    img = model(noise)    # Генерация изображения\n",
    "\n",
    "    return Model(noise, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Конструктор дискриминатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Flatten(input_shape=img_shape))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(256))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "\n",
    "    img = Input(shape=img_shape)\n",
    "    validity = model(img)\n",
    "\n",
    "    return Model(img, validity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функции для сохранения и загрузки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model, save_model\n",
    "import os\n",
    "\n",
    "models_path = r'model'\n",
    "gan_path = models_path + '\\\\' + \"gan\"\n",
    "generator_path = models_path + '\\\\' + \"generator\"\n",
    "discriminator_path = models_path + '\\\\' + \"discriminator\"\n",
    "\n",
    "Path(gan_path).mkdir(parents=True, exist_ok=True)\n",
    "Path(generator_path).mkdir(parents=True, exist_ok=True)\n",
    "Path(discriminator_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save(gan, generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    save_model(gan, gan_path)\n",
    "    discriminator.trainable = True\n",
    "    save_model(generator, generator_path)\n",
    "    save_model(discriminator, discriminator_path)\n",
    "\n",
    "def load():\n",
    "    discriminator = load_model(discriminator_path)\n",
    "    generator = load_model(generator_path)\n",
    "    gan = load_model(gan_path)\n",
    "    gan.summary()\n",
    "    discriminator.summary()\n",
    "    generator.summary()\n",
    "\n",
    "    return gan, generator, discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = np.load('mnist_imgs.npy')\n",
    "(X_train, _), (_, _) = mnist.load_data()\n",
    "#X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "X_train = X_train.astype(np.float32) / 255.0\n",
    "img_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(np.max(X_train[0]))\n",
    "print(np.min(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_22 (InputLayer)       [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " sequential_15 (Sequential)  (None, 1)                 533505    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 533,505\n",
      "Trainable params: 0\n",
      "Non-trainable params: 533,505\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = build_discriminator()\n",
    "discriminator.trainable = False\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(0.00001, 0.5), metrics=['accuracy'])\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_24 (InputLayer)       [(None, 100)]             0         \n",
      "                                                                 \n",
      " sequential_17 (Sequential)  (None, 28, 28, 1)         1493520   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,493,520\n",
      "Trainable params: 1,489,936\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = build_generator()\n",
    "generator.compile(loss='binary_crossentropy', optimizer=Adam(0.0001, 0.5))\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_25 (InputLayer)       [(None, 100)]             0         \n",
      "                                                                 \n",
      " model_23 (Functional)       (None, 28, 28, 1)         1493520   \n",
      "                                                                 \n",
      " model_21 (Functional)       (None, 1)                 533505    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,027,025\n",
      "Trainable params: 2,023,441\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "z = Input(shape=(100,))\n",
    "img = generator(z)\n",
    "\n",
    "valid = discriminator(img)  #Проверка достоверности сгенерированного изображения\n",
    "\n",
    "combined = Model(z, valid)\n",
    "combined.compile(loss='binary_crossentropy', optimizer=Adam(0.00002, 0.5))\n",
    "combined.trainable = True\n",
    "combined.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, batch_size=128, save_interval=50):\n",
    "    half_batch = int(batch_size / 2)\n",
    "    progress = tqdm(total=epochs)\n",
    "    for epoch in range(epochs):\n",
    "        idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "        imgs = X_train[idx]\n",
    " \n",
    "        noise = np.random.normal(0, 1, (half_batch, 100))\n",
    "\n",
    "        gen_imgs = generator.predict(noise, verbose=0)\n",
    "\n",
    "        d_loss_real = discriminator.train_on_batch(imgs, np.ones((half_batch, 1))) \n",
    "        d_loss_fake = discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "    \n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake) \n",
    "\n",
    "        noise = np.random.normal(0, 1, (batch_size, 100)) \n",
    "\n",
    "        valid_y = np.array([1] * batch_size)\n",
    "        g_loss = combined.train_on_batch(noise, valid_y)\n",
    "\n",
    "\n",
    "        # Дополнительно, чтобы мы могли отслеживать процесс обучения, мы выводим на печать\n",
    "        # прогресс и сохраняем вывод образцов изображений в зависимости от заданного интервала эпох, \n",
    "        # а также по желанию, можем сохранять модель.  \n",
    "        status = \"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss)\n",
    "        progress.set_description_str(status)\n",
    "        progress.update(1)\n",
    "\n",
    "        # If at save interval => save generated image samples\n",
    "        if epoch % save_interval == 0:\n",
    "            progress.write(\"Saving images...\")\n",
    "            save_imgs(epoch)\n",
    "            if epoch % 1000 == 0:\n",
    "                # save(combined, generator, discriminator)\n",
    "                progress.write(\"Saving models...\")\n",
    "                save(combined, generator, discriminator)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_imgs(epoch):\n",
    "    r, c = 5, 5\n",
    "    noise = np.random.normal(0, 1, (r * c, 100))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "            axs[i,j].axis('off')\n",
    "            cnt += 1\n",
    "            \n",
    "    Path('gen_images').mkdir(parents=True, exist_ok=True)\n",
    "    fig.savefig('gen_images' + '\\\\' + f'epoch_{epoch}.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "715205345f8b4dc193634f5b8d83a805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving images...\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Saving models...\n",
      "INFO:tensorflow:Assets written to: model\\gan\\assets\n",
      "INFO:tensorflow:Assets written to: model\\generator\\assets\n",
      "INFO:tensorflow:Assets written to: model\\discriminator\\assets\n",
      "Saving images...\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Saving models...\n",
      "INFO:tensorflow:Assets written to: model\\gan\\assets\n",
      "INFO:tensorflow:Assets written to: model\\generator\\assets\n",
      "INFO:tensorflow:Assets written to: model\\discriminator\\assets\n",
      "Saving images...\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Saving models...\n",
      "INFO:tensorflow:Assets written to: model\\gan\\assets\n",
      "INFO:tensorflow:Assets written to: model\\generator\\assets\n",
      "INFO:tensorflow:Assets written to: model\\discriminator\\assets\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[115], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m generator\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerator_model_final_4.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[112], line 10\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epochs, batch_size, save_interval)\u001b[0m\n\u001b[0;32m      6\u001b[0m imgs \u001b[38;5;241m=\u001b[39m X_train[idx]\n\u001b[0;32m      8\u001b[0m noise \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, (half_batch, \u001b[38;5;241m100\u001b[39m))\n\u001b[1;32m---> 10\u001b[0m gen_imgs \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m d_loss_real \u001b[38;5;241m=\u001b[39m discriminator\u001b[38;5;241m.\u001b[39mtrain_on_batch(imgs, np\u001b[38;5;241m.\u001b[39mones((half_batch, \u001b[38;5;241m1\u001b[39m))) \n\u001b[0;32m     13\u001b[0m d_loss_fake \u001b[38;5;241m=\u001b[39m discriminator\u001b[38;5;241m.\u001b[39mtrain_on_batch(gen_imgs, np\u001b[38;5;241m.\u001b[39mzeros((half_batch, \u001b[38;5;241m1\u001b[39m)))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\keras\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\keras\\lib\\site-packages\\keras\\engine\\training.py:2253\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2251\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[0;32m   2252\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_begin(step)\n\u001b[1;32m-> 2253\u001b[0m     tmp_batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2254\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   2255\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    952\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    957\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(epochs=25000, batch_size=256, save_interval=2000)\n",
    "\n",
    "generator.save('generator_model_final_4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_batch = int(256 / 2)\n",
    "noise = np.random.normal(0, 1, (half_batch, 100))\n",
    "\n",
    "gen_imgs = generator.predict(noise, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 75ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.9168278]], dtype=float32)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator.predict(gen_imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 100)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plt.figure()\n",
    "#plt.imshow(noise, cmap='gray')\n",
    "\n",
    "noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x197dcb26fa0>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(gen_imgs[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zv1ffB3n3vp1"
   },
   "source": [
    "### Демонстрация сгенерированных изображений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VG9s1jAC3vp1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eT9gIMd82bMA"
   },
   "source": [
    "# **Задание №2.** Обучите генератор воспризводить сложные изображения. Датасет выберите по желанию. ([Пример](https://www.kaggle.com/datasets/fedesoriano/cifar100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4eHIIsE32a_5"
   },
   "outputs": [],
   "source": [
    "https://www.kaggle.com/datasets/fedesoriano/cifar100# Ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0xLo1r72RqP"
   },
   "source": [
    "### Демонстрация сгенерированных изображений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yv6VHkoh2Wkz"
   },
   "outputs": [],
   "source": [
    "# Ваш код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "-5vsrYXt1Rk8",
    "eT9gIMd82bMA"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
